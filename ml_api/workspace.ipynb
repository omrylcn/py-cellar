{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from app.core.config import settings\n",
    "from app.utils.object_storage import ObjectStorage\n",
    "from app.services.nlp import QAService\n",
    "from app.core.logging import FileLogger, MongoDBLogger,DBLogger\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from pydantic_settings import BaseSettings\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curl -X 'POST' \\\n",
    "  'http://localhost:8000/api/v1/qa/answer' \\\n",
    "  -H 'accept: application/json' \\\n",
    "  -H 'Content-Type: application/json' \\\n",
    "  -d '{\n",
    "  \"question\": \"what is capital of france\",\n",
    "  \"context\": \"paris is capital of france\"\n",
    "}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://localhost:8000/api/v1/qa/answer\"\n",
    "data = {\n",
    "    \"question\": \"What is the capital of France?\",\n",
    "    \"context\": \"Paris is the capital of France.\"\n",
    "}\n",
    "requests.post(url, json=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(200):\n",
    "    requests.post(url, json=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_dict= {\n",
    "    \"model_name\": \"qa_model\",\n",
    "    \"model_tag\": \"v1\",\n",
    "    \"model_version\": \"1.0\",\n",
    "    \"name\":\"qa_model-v1-1-0\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_logger = DBLogger(logger=settings.LOGGER_HANDLER,**p_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_logger.log_operation(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = QAService()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa.predict(question=\"What is the capital of France?\", context=\"Paris and Madrid are both of capitals in Europe. Madrid is the capital of Spain.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings.LOGGER_HANDLER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings.LOG_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = MongoDBLogger(db_name=\"test\", model_name=\"test\", model_tag=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.log_operation(\"test_meesage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QAService:\n",
    "    def __init__(self, db_logger_wrapper: DBLoggerWrapper, settings: Any = None):\n",
    "        self.settings = settings\n",
    "        self.model = None\n",
    "        self.model_name = self.settings.QA_NAME\n",
    "        self.model_tag = self.settings.QA_TAG\n",
    "        \n",
    "        self.db_logger = db_logger_wrapper\n",
    "        \n",
    "        self.load_model()\n",
    "        self.model.eval()\n",
    "\n",
    "    def load_model(self):\n",
    "        try:\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(self.settings.QA_MODEL_PATH)\n",
    "            self.model = AutoModelForQuestionAnswering.from_pretrained(self.settings.QA_MODEL_PATH)\n",
    "            self.db_logger.log_operation(f\"Model loaded successfully: {self.settings.QA_MODEL_PATH}\")\n",
    "            self.db_logger.log_metadata({\n",
    "                \"model_path\": self.settings.QA_MODEL_PATH,\n",
    "                \"tokenizer_type\": type(self.tokenizer).__name__,\n",
    "                \"model_type\": type(self.model).__name__\n",
    "            })\n",
    "        except Exception as e:\n",
    "            self.db_logger.log_operation(f\"Error loading model: {str(e)}\", \"error\", exc_info=True)\n",
    "            raise\n",
    "\n",
    "    def answer_question(self, question: str, context: str):\n",
    "        try:\n",
    "            inputs = self.tokenizer(question, context, return_tensors=\"pt\")\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**inputs)\n",
    "\n",
    "            start_scores = outputs.start_logits\n",
    "            end_scores = outputs.end_logits\n",
    "\n",
    "            start_index = torch.argmax(start_scores)\n",
    "            end_index = torch.argmax(end_scores)\n",
    "\n",
    "            answer_tokens = inputs[\"input_ids\"][0][start_index : end_index + 1]\n",
    "            answer = self.tokenizer.decode(answer_tokens)\n",
    "\n",
    "            result = {\"answer\": answer, \"start\": int(start_index), \"end\": int(end_index)}\n",
    "    \n",
    "            self.db_logger.log_model_results({\n",
    "                \"question_length\": len(question),\n",
    "                \"context_length\": len(context),\n",
    "                \"answer_length\": len(answer)\n",
    "            })\n",
    "\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            self.db_logger.log_operation(f\"Error answering question: {str(e)}\", \"error\", exc_info=True)\n",
    "            raise\n",
    "\n",
    "    def predict(self, question: str, context: str):\n",
    "        return self.answer_question(question, context)\n",
    "\n",
    "    def get_prediction(self, prediction_id: str):\n",
    "        raise NotImplementedError(\"This method is not implemented in the QAService class.\")\n",
    "        # return self.db_logger.get_prediction(prediction_id)\n",
    "\n",
    "    def get_model_performance(self, start_date: datetime, end_date: datetime):\n",
    "        return self.db_logger.get_model_performance(start_date, end_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.log_operation(\"This is a test log message.\", level=\"info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self._store_prediction(question, context, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "            inputs = self.tokenizer(question, context, return_tensors=\"pt\")\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**inputs)\n",
    "\n",
    "            start_scores = outputs.start_logits\n",
    "            end_scores = outputs.end_logits\n",
    "\n",
    "            start_index = torch.argmax(start_scores)\n",
    "            end_index = torch.argmax(end_scores)\n",
    "\n",
    "            answer_tokens = inputs[\"input_ids\"][0][start_index : end_index + 1]\n",
    "            answer = self.tokenizer.decode(answer_tokens)\n",
    "\n",
    "            result = {\"answer\": answer, \"start\": int(start_index), \"end\": int(end_index)}\n",
    "\n",
    "            self.db_logger.log_model_results(\n",
    "                input_info={\"question\": question, \"context\": context},\n",
    "                results={\"question_length\": len(question), \"context_length\": len(context), \"answer_length\": len(answer)}\n",
    "            )\n",
    "\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            self.db_logger.log_operation(f\"Error answering question: {str(e)}\", \"error\", exc_info=True)\n",
    "            raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelSettings(BaseSettings):\n",
    "    MODEL_NAME: str = \"model_name\"  \n",
    "    MODEL_VERSION: str = \"model_version\"\n",
    "\n",
    "\n",
    "\n",
    " model_config = ModelSettings(MODEL_NAME=settings.QA_NAME)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa.storage.store_object?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = QAService()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa.predict(\"What is the capital of France?\", \"France is a country in Europe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa.answer_question(\"What is the capital of France?\", \"Paris is the capital of France.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = ObjectStorage(endpoint=settings.MINIO_ENDPOINT, access_key=settings.MINIO_ACCESS_KEY, secret_key=settings.MINIO_SECRET_KEY, secure=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.core.config import settings,load_config_yaml\n",
    "from pydantic_settings import BaseSettingsaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_settings import (\n",
    "    BaseSettings,\n",
    "    SettingsConfigDict,\n",
    "    PydanticBaseSettingsSource,\n",
    "    YamlConfigSettingsSource\n",
    ")\n",
    "from pydantic import Field\n",
    "from typing import Tuple, Type\n",
    "\n",
    "\n",
    "class Settings(BaseSettings):\n",
    "    # Define your settings here with default values\n",
    "    PROJECT_NAME: str = Field(default=\"ML API_0\")\n",
    "    PROJECT_VERSION: str = Field(default=\"0.0.0\")\n",
    "    PORT: int = Field(default=8000)\n",
    "    \n",
    "    \n",
    "    # CLIP_ENABLE: bool = Field(default=False)\n",
    "    # QA_ENABLE: bool = Field(default=False)\n",
    "\n",
    "    # # Add other settings as needed\n",
    "    # CLIP_MODEL_PATH: str = Field(default=\"\")\n",
    "    # QA_MODEL_PATH: str = Field(default=\"\")\n",
    "    \n",
    "\n",
    "    model_config = SettingsConfigDict(\n",
    "        env_file='.env',\n",
    "        env_file_encoding='utf-8',\n",
    "        extra=\"allow\",\n",
    "        yaml_file=\"config/config.yaml\",\n",
    "        case_sensitive=True\n",
    "    )\n",
    "\n",
    "    @classmethod\n",
    "    def settings_customise_sources(\n",
    "        cls,\n",
    "        settings_cls: Type[BaseSettings],\n",
    "        init_settings: PydanticBaseSettingsSource,\n",
    "        env_settings: PydanticBaseSettingsSource,\n",
    "        dotenv_settings: PydanticBaseSettingsSource,\n",
    "        file_secret_settings: PydanticBaseSettingsSource,\n",
    "    ) -> Tuple[PydanticBaseSettingsSource, ...]:\n",
    "        \n",
    "        return (      \n",
    "           # env_settings,\n",
    "          #  file_secret_settings,\n",
    "            dotenv_settings,\n",
    "            YamlConfigSettingsSource(settings_cls),\n",
    "            init_settings,\n",
    "            \n",
    "        )\n",
    "# Instantiate the settings\n",
    "Settings().model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_settings import BaseSettings, SettingsConfigDict\n",
    "from pydantic import Field, validator\n",
    "from omegaconf import OmegaConf\n",
    "from typing import Dict, Any\n",
    "import os\n",
    "\n",
    "class Settings(BaseSettings):\n",
    "    CONFIG_PATH: str = Field(default=\"config/config.yaml\")\n",
    "\n",
    "    # Define your settings fields here. These will be populated from the YAML file.\n",
    "    PROJECT_NAME: str = Field(default=\"ML API_0\")\n",
    "    PROJECT_VERSION: str = Field(default=\"0.0.0\")\n",
    "    CLIP_ENABLE: bool = Field(default=False)\n",
    "    QA_ENABLE: bool = Field(default=False)\n",
    "\n",
    "    # Add other fields as needed\n",
    "    # CLIP_MODEL_PATH: str\n",
    "    # QA_MODEL_PATH: str\n",
    "    # PORT: int\n",
    "\n",
    "    model_config = SettingsConfigDict(\n",
    "        env_file=\".env\",\n",
    "        env_file_encoding=\"utf-8\",\n",
    "        extra=\"allow\",\n",
    "    )\n",
    "\n",
    "    @validator(\"*\", pre=True)\n",
    "    def load_yaml_config(cls, v, field):\n",
    "        config_path = os.getenv(\"CONFIG_PATH\", cls.CONFIG_PATH)\n",
    "        if os.path.exists(config_path):\n",
    "            config = OmegaConf.load(config_path)\n",
    "            if field.name in config:\n",
    "                return config[field.name]\n",
    "        return v\n",
    "\n",
    "    class Config:\n",
    "        validate_assignment = True\n",
    "\n",
    "settings = Settings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_settings import BaseSettings, SettingsConfigDict\n",
    "from pydantic import Field\n",
    "from omegaconf import OmegaConf\n",
    "from typing import Dict, Any\n",
    "import os\n",
    "\n",
    "CONFIG_YAML_PATH = \"config/config.yaml\"\n",
    "\n",
    "def load_config_yaml() -> Dict[str, Any]:\n",
    "    if os.path.exists(CONFIG_YAML_PATH):\n",
    "        config = OmegaConf.load(CONFIG_YAML_PATH)\n",
    "        return OmegaConf.to_container(config, resolve=True)\n",
    "    return {}\n",
    "\n",
    "class Settings(BaseSettings):\n",
    "    PROJECT_NAME: str = Field(default=\"ML API_0\")\n",
    "    PROJECT_VERSION: str = Field(default=\"0.0.0\")\n",
    "    CLIP_ENABLE: bool = Field(default=False)\n",
    "    QA_ENABLE: bool = Field(default=False)\n",
    "\n",
    "    # Add other fields as needed\n",
    "    # CLIP_MODEL_PATH: str = Field(default=\"ml/siglip-base-patch16-224.xml\")\n",
    "    # QA_MODEL_PATH: str = Field(default=\"distilbert-base-cased-distilled-squad\")\n",
    "    # PORT: int = Field(default=8000)\n",
    "\n",
    "    # model_config = SettingsConfigDict(\n",
    "    #     env_file=\".env\",\n",
    "    #     env_file_encoding=\"utf-8\",\n",
    "    #     extra=\"allow\",\n",
    "    # )\n",
    "\n",
    "    @classmethod\n",
    "    def settings_customise_sources(\n",
    "        cls,\n",
    "     \n",
    "        init_settings,\n",
    "        env_settings,\n",
    "        file_secret_settings,\n",
    "    ):\n",
    "        yaml_settings = load_config_yaml()\n",
    "        return (\n",
    "            init_settings,\n",
    "            #yaml_settings,\n",
    "            env_settings,\n",
    "            file_secret_settings,\n",
    "        )\n",
    "\n",
    "\n",
    "settings = Settings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = getattr(settings,\"PORT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from typing import Dict, Any\n",
    "from pydantic_settings import BaseSettings\n",
    "from pydantic import Field\n",
    "\n",
    "def yaml_config_settings_source(settings: BaseSettings) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    A simple settings source that loads variables from a YAML file\n",
    "    at the project's root.\n",
    "    \"\"\"\n",
    "    with open(\"config.yaml\", \"r\") as yaml_file:\n",
    "        return yaml.safe_load(yaml_file)\n",
    "\n",
    "class Settings(BaseSettings):\n",
    "    PROJECT_NAME: str = Field(default=\"ML API\")\n",
    "    PROJECT_VERSION: str = Field(default=\"1.0.0\")\n",
    "\n",
    "    # Model paths\n",
    "    CLIP_MODEL_PATH: str = Field(default=\"ml/siglip-base-patch16-224.xml\")\n",
    "    QA_MODEL_PATH: str = Field(default=\"distilbert-base-cased-distilled-squad\")\n",
    "\n",
    "    # Feature flags\n",
    "    CLIP_ENABLE: bool = Field(default=False)\n",
    "    QA_ENABLE: bool = Field(default=False)\n",
    "\n",
    "    PORT: int = Field(default=8000)\n",
    "\n",
    "    # MinIO settings\n",
    "    MINIO_ENDPOINT: str = Field(default=\"minio:9000\")\n",
    "    MINIO_ACCESS_KEY: str = Field(default=\"minioadmin\")\n",
    "    MINIO_SECRET_KEY: str = Field(default=\"minioadmin\")\n",
    "    MINIO_SECURE: bool = Field(default=False)\n",
    "\n",
    "    class Config:\n",
    "        env_file = \".env\"\n",
    "        env_file_encoding = 'utf-8'\n",
    "        extra = 'ignore'\n",
    "\n",
    "        @classmethod\n",
    "        def customise_sources(\n",
    "            cls,\n",
    "            init_settings,\n",
    "            env_settings,\n",
    "            file_secret_settings,\n",
    "        ):\n",
    "            return (\n",
    "                init_settings,\n",
    "                yaml_config_settings_source,\n",
    "                env_settings,\n",
    "                file_secret_settings,\n",
    "            )\n",
    "\n",
    "settings = Settings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"distilbert-base-cased-distilled-squad\"\n",
    "\n",
    "pipeline(model=model_name, tokenizer=model_name, task='question-answering')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"distilbert-base-cased-distilled-squad\"\n",
    "\n",
    "model = pipeline(model=model_name, tokenizer=model_name, task='question-answering')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(\"is football sport ?\", \"Football is a family of team sports that involve, to varying degrees, kicking a ball to score a goal. Unqualified, the word football generally means the form of football that is the most popular where the word is used.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.services.nlp import QAService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = QAService()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa.answer_question(\"What is the capital of France?\",\"Football is a team sport played between two teams of eleven players with a spherical ball. It is played by 250 million players in over 200 countries and dependencies, making it the world's most popular sport.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
