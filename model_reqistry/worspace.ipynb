{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from registry.client import ModelRegistryClient\n",
    "import os\n",
    "import io\n",
    "from datetime import datetime\n",
    "from datetime import datetime\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from registry.schemas import ModelMetadata\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = ModelRegistryClient(base_url=\"http://localhost:8000\")\n",
    "client.health_check()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "X = np.random.rand(100, 2)\n",
    "y = np.random.randint(0, 2, 100)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "model_buffer = io.BytesIO()\n",
    "pickle.dump(model, model_buffer)\n",
    "model_buffer.seek(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = ModelMetadata(\n",
    "            id=\"model123\",\n",
    "            name=\"example_model\",\n",
    "            version=\"1.0.0\",\n",
    "            file_extension=\"pkl\",\n",
    "            storage_group=\"ml-models\",\n",
    "            description=\"Example model\",\n",
    "            framework=\"scikit-learn\",\n",
    "            metrics={\"accuracy\": 0.95},\n",
    "            parameters={\"n_estimators\": 100}\n",
    "        )\n",
    "res = client.upload_model(model_buffer, metadata)\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_path = res.file_path\n",
    "metadata_id = res.metadata_id\n",
    "res = client.get_model_buffer(file_path, metadata_id)\n",
    "model = pickle.load(res[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Registry Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from registry.registry import ModelRegistry\n",
    "from registry.schemas import ModelMetadata\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Create sample model\n",
    "X = np.random.rand(100, 2)\n",
    "y = np.random.randint(0, 2, 100)\n",
    "sample_model = {\"data\": (X, y)}\n",
    "\n",
    "with open(\"test_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(sample_model, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bufferr = io.BytesIO()\n",
    "pickle.dump(sample_model,model_bufferr)\n",
    "model_bufferr.seek(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = ModelMetadata(\n",
    "    id= datetime.now().strftime(\"%d%m%Y%H%M%S\"),\n",
    "    name=\"memory_test_model\",\n",
    "    file_extension=\".pkl\",\n",
    "    storage_group=\"test-project\",\n",
    "    version=\"1.0.0\",\n",
    "    framework=\"sk\",\n",
    "    description=\"In-memory test of logistic regression model\",\n",
    "    metrics={\n",
    "        \"train_accuracy\": float(0.6),\n",
    "        \"test_accuracy\": float(0.6)\n",
    "    },\n",
    "    parameters={\n",
    "        \"n_features\": X.shape[1],\n",
    "        \"n_samples\": X.shape[0],\n",
    "        \"model_type\": \"LogisticRegression\",\n",
    "        \"model_params\": {\"a\":12}\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "model_reg = ModelRegistry()\n",
    "\n",
    "res = model_reg.register_model(model_bufferr,metadata.model_dump())\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### API Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import io\n",
    "import json\n",
    "import pickle\n",
    "import requests\n",
    "\n",
    "import numpy as np\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from registry.schemas import ModelMetadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 1 # 1 is pickle\n",
    "\n",
    "if mode == 1:\n",
    "\n",
    "    # Create sample model\n",
    "    X = np.random.rand(100, 2)\n",
    "    y = np.random.randint(0, 2, 100)\n",
    "    sample_model = {\"data\": (X, y)}\n",
    "\n",
    "    with open(\"test_model.pkl\", \"wb\") as f:\n",
    "        pickle.dump(sample_model, f)\n",
    "\n",
    "    # First, let's fix the ModelMetadata instance\n",
    "    metadata = ModelMetadata(\n",
    "        id=datetime.now().strftime(\"%d%m%Y%H%M%S\"),\n",
    "        name=\"memory_test_model\",\n",
    "        file_extension=\"pkl\",  # Remove the dot (.) from extension\n",
    "        storage_group=\"test-project\",\n",
    "        version=\"1.0.0\",\n",
    "        framework=\"sk\",\n",
    "        description=\"In-memory test of logistic regression model\",\n",
    "        metrics={\n",
    "            \"train_accuracy\": float(0.6),\n",
    "            \"test_accuracy\": float(0.6)\n",
    "        },\n",
    "        parameters={\n",
    "            \"n_features\": X.shape[1],\n",
    "            \"n_samples\": X.shape[0],\n",
    "            \"model_type\": \"LogisticRegression\",\n",
    "            \"model_params\": {\"a\": 12}\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    # Create in-memory model buffer\n",
    "    model_buffer = io.BytesIO()\n",
    "    pickle.dump(sample_model, model_buffer)\n",
    "    model_buffer.seek(0)\n",
    "\n",
    "    # Prepare files for upload\n",
    "    files = {\n",
    "        'metadata': (None, json.dumps(metadata.model_dump())),  # Convert to dict first, then to JSON\n",
    "        'model_file': (\n",
    "            'model.pkl',\n",
    "            model_buffer,\n",
    "            'application/octet-stream'\n",
    "        )\n",
    "    }\n",
    "\n",
    "    # Make request\n",
    "    response = requests.post(\n",
    "        url='http://localhost:8000/models/upload',\n",
    "        files=files,\n",
    "        headers={'accept': 'application/json'}\n",
    "    )\n",
    "\n",
    "\n",
    "else:\n",
    "# Create and train a proper ML model\n",
    "    # Generate sample data\n",
    "    np.random.seed(42)\n",
    "    X = np.random.rand(100, 2)\n",
    "    y = np.random.randint(0, 2, 100)\n",
    "\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Create and train the model\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Calculate metrics\n",
    "    train_accuracy = model.score(X_train, y_train)\n",
    "    test_accuracy = model.score(X_test, y_test)\n",
    "\n",
    "    # Convert to ONNX\n",
    "    initial_type = [('float_input', FloatTensorType([None, 2]))]\n",
    "    onnx_model = convert_sklearn(model, initial_types=initial_type)\n",
    "\n",
    "    # Create metadata\n",
    "    metadata = ModelMetadata(\n",
    "        id=datetime.now().strftime(\"%d%m%Y%H%M%S\"),\n",
    "        name=\"onnx_test_model\",\n",
    "        file_extension=\"onnx\",\n",
    "        storage_group=\"test-project\",\n",
    "        version=\"1.0.0\",\n",
    "        framework=\"onnx\",\n",
    "        description=\"ONNX converted logistic regression model\",\n",
    "        metrics={\n",
    "            \"train_accuracy\": float(train_accuracy),\n",
    "            \"test_accuracy\": float(test_accuracy)\n",
    "        },\n",
    "        parameters={\n",
    "            \"n_features\": X.shape[1],\n",
    "            \"n_samples\": X.shape[0],\n",
    "            \"model_type\": \"LogisticRegression\",\n",
    "            \"model_params\": model.get_params()\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Create in-memory model buffer\n",
    "    model_buffer = io.BytesIO()\n",
    "    model_buffer.write(onnx_model.SerializeToString())\n",
    "    model_buffer.seek(0)\n",
    "\n",
    "    # Prepare files for upload\n",
    "    files = {\n",
    "        'metadata': (None, json.dumps(metadata.model_dump())),\n",
    "        'model_file': (\n",
    "            'model.onnx',\n",
    "            model_buffer,\n",
    "            'application/octet-stream'\n",
    "        )\n",
    "    }\n",
    "\n",
    "    # Make request\n",
    "    response = requests.post(\n",
    "        url='http://localhost:8000/models/upload',\n",
    "        files=files,\n",
    "        headers={'accept': 'application/json'}\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"API Response :\",response)\n",
    "print(f\"Upload response status code: {response.status_code}\")\n",
    "print(f\"Response content: {response.json()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make request\n",
    "response = requests.post(\n",
    "    url='http://localhost:8000/models/upload',\n",
    "    files=files,\n",
    "    headers={'accept': 'application/json'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_json = response.json()\n",
    "response_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path =  response_json[\"storage_path\"]\n",
    "metadata_id = response_json[\"metadata_id\"]\n",
    "url = \"http://localhost:8000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(f\"http://localhost:8000/models/metadata/{file_path}?metadata_id={metadata_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(f\"http://localhost:8000/models/file/{file_path}?metadata_id={metadata_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in response.iter_content():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
